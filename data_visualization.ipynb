{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Project 20211"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing librairies\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Scikit-learn library: For SVM\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Matplotlib library to plot the charts\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "\n",
    "# Library for the statistic data vizualisation\n",
    "import seaborn\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    " \n",
    "responses = df.groupBy('feedback').count().collect()\n",
    "categories = [i[0] for i in responses]\n",
    "counts = [i[1] for i in responses]\n",
    " \n",
    "ind = np.array(range(len(categories)))\n",
    "width = 0.35\n",
    "plt.bar(ind, counts, width=width, color='r')\n",
    " \n",
    "plt.ylabel('counts')\n",
    "plt.title('Response distribution')\n",
    "plt.xticks(ind + width/2., categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    " \n",
    "binarize = lambda x: 'Negative' if x == 'Neutral' else x\n",
    " \n",
    "udfValueToCategory = udf(binarize, StringType())\n",
    "df = df.withColumn(\"binary_response\", udfConvertResponse(\"feedback\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_select = ['prod_price',\n",
    "               'prod_feat_1',\n",
    "               'prod_feat_2',\n",
    "               'cust_age',\n",
    "               'prod_feat_3',\n",
    "               'cust_region',\n",
    "               'prod_type',\n",
    "               'cust_sex',\n",
    "               'cust_title',\n",
    "               'feedback',\n",
    "               'binary_response']\n",
    " \n",
    "df = df.select(df.prod_price.cast('float'), # convert numeric cols (int or float) into a 'int' or 'float'\n",
    "               df.prod_feat_1.cast('float'),\n",
    "               df.prod_feat_2.cast('float'),\n",
    "               df.cust_age.cast('int'),\n",
    "               *cols_select[4:])\n",
    " \n",
    "df = df.fillna({'cust_region': 'NA', 'cust_title': 'NA', 'prod_type': 'NA'}) # fill in 'N/A' entries for certain cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    " \n",
    "COUNT_THRESHOLD = 150 # threshold to filter \n",
    " \n",
    "# create a temporary col \"count\" as counting for each value of \"prod_feat_3\"\n",
    "prodFeat3Count = df.groupBy(\"prod_feat_3\").count()\n",
    "df = df.join(prodFeat3Count, \"prod_feat_3\", \"inner\")\n",
    " \n",
    "def convertMinority(originalCol, colCount):\n",
    "    if colCount > COUNT_THRESHOLD:\n",
    "        return originalCol\n",
    "    else:\n",
    "        return 'MinorityCategory'\n",
    "createNewColFromTwo = udf(convertMinority, StringType())\n",
    "df = df.withColumn('prod_feat_3_reduced', createNewColFromTwo(df['prod_feat_3'], df['count']))\n",
    "df = df.drop('prod_feat_3')\n",
    "df = df.drop('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "column_vec_in = ['prod_feat_3_reduced', 'cust_region', 'prod_type', 'cust_sex', 'cust_title']\n",
    "column_vec_out = ['prod_feat_3_reduced_catVec','cust_region_catVec', 'prod_type_catVec','cust_sex_catVec',\n",
    "'cust_title_catVec']\n",
    " \n",
    "indexers = [StringIndexer(inputCol=x, outputCol=x+'_tmp')\n",
    "            for x in column_vec_in ]\n",
    " \n",
    "encoders = [OneHotEncoder(dropLast=False, inputCol=x+\"_tmp\", outputCol=y)\n",
    "for x,y in zip(column_vec_in, column_vec_out)]\n",
    "tmp = [[i,j] for i,j in zip(indexers, encoders)]\n",
    "tmp = [i for sublist in tmp for i in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare labeled sets\n",
    "cols_now = ['prod_price',\n",
    "            'prod_feat_1',\n",
    "            'prod_feat_2',\n",
    "            'cust_age',\n",
    "            'prod_feat_3_reduced_catVec',\n",
    "            'cust_region_catVec',\n",
    "            'prod_type_catVec',\n",
    "            'cust_sex_catVec',\n",
    "            'cust_title_catVec']\n",
    "assembler_features = VectorAssembler(inputCols=cols_now, outputCol='features')\n",
    "labelIndexer = StringIndexer(inputCol='binary_response', outputCol=\"label\")\n",
    "tmp += [assembler_features, labelIndexer]\n",
    "pipeline = Pipeline(stages=tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allData = pipeline.fit(df).transform(df)\n",
    "allData.cache()\n",
    "trainingData, testData = allData.randomSplit([0.8,0.2], seed=0) # need to ensure same split for each time\n",
    "print(\"Distribution of Pos and Neg in trainingData is: \", trainingData.groupBy(\"label\").count().take(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RF(labelCol='label', featuresCol='features',numTrees=200)\n",
    "fit = rf.fit(trainingData)\n",
    "transformed = fit.transform(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics as metric\n",
    "results = transformed.select(['probability', 'label'])\n",
    " \n",
    "## prepare score-label set\n",
    "results_collect = results.collect()\n",
    "results_list = [(float(i[0][0]), 1.0-float(i[1])) for i in results_collect]\n",
    "scoreAndLabels = sc.parallelize(results_list)\n",
    " \n",
    "metrics = metric(scoreAndLabels)\n",
    "print(\"The ROC score is (@numTrees=200): \", metrics.areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot AUC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    " \n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    " \n",
    "y_test = [i[1] for i in results_list]\n",
    "y_score = [i[0] for i in results_list]\n",
    " \n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    " \n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Down Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import randint\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    " \n",
    "RATIO_ADJUST = 2.0 ## ratio of pos to neg in the df_subsample\n",
    " \n",
    "counts = trainingData.select('binary_response').groupBy('binary_response').count().collect()\n",
    "higherBound = counts[0][1]\n",
    "TRESHOLD_TO_FILTER = int(RATIO_ADJUST * float(counts[1][1]) / counts[0][1] * higherBound)\n",
    " \n",
    "randGen = lambda x: randint(0, higherBound) if x == 'Positive' else -1\n",
    " \n",
    "udfRandGen = udf(randGen, IntegerType())\n",
    "trainingData = trainingData.withColumn(\"randIndex\", udfRandGen(\"binary_response\"))\n",
    "df_subsample = trainingData.filter(trainingData['randIndex'] < TRESHOLD_TO_FILTER)\n",
    "df_subsample = df_subsample.drop('randIndex')\n",
    " \n",
    "print(\"Distribution of Pos and Neg cases of the down-sampled training data are: \\n\", df_subsample.groupBy(\"label\").count().take(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## training and prediction\n",
    "rf = RF(labelCol='label', featuresCol='features',numTrees=200)\n",
    "fit = rf.fit(df_subsample)\n",
    "transformed = fit.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## results and evaluation\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics as metric\n",
    "results = transformed.select(['probability', 'label'])\n",
    " \n",
    "results_collect = results.collect()\n",
    "results_list = [(float(i[0][0]), 1.0-float(i[1])) for i in results_collect]\n",
    "scoreAndLabels = sc.parallelize(results_list)\n",
    " \n",
    "metrics = metric(scoreAndLabels)\n",
    "print(\"The ROC score is (@numTrees=200): \", metrics.areaUnderROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble of Down-samplings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import randint\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics as metric\n",
    " \n",
    "RATIO_ADJUST = 3.0 ## ratio of pos to neg in the df_subsample\n",
    "TOTAL_MODELS = 10\n",
    "total_results = None\n",
    "final_result = None\n",
    " \n",
    "#counts = trainingData.select('binary_response').groupBy('binary_response').count().collect()\n",
    "highestBound = counts[0][1]\n",
    "TRESHOLD_TO_FILTER = int(RATIO_ADJUST * float(counts[1][1]) / counts[0][1] * highestBound)\n",
    "## UDF\n",
    "randGen = lambda x: randint(0, highestBound) if x == 'Positive' else -1\n",
    "udfRandGen = udf(randGen, IntegerType())\n",
    " \n",
    "## ensembling\n",
    "for N in range(TOTAL_MODELS):\n",
    "    print(\"Round: \", N)\n",
    "    trainingDataIndexed = trainingData.withColumn(\"randIndex\", udfRandGen(\"binary_response\"))\n",
    "    df_subsample = trainingDataIndexed.filter(trainingDataIndexed['randIndex'] < TRESHOLD_TO_FILTER).drop('randIndex')\n",
    "    ## training and prediction\n",
    "    rf = RF(labelCol='label', featuresCol='features',numTrees=200)\n",
    "    fit = rf.fit(df_subsample)\n",
    "    transformed = fit.transform(testData)\n",
    "    result_pair = transformed.select(['probability', 'label'])\n",
    "    result_pair = result_pair.collect()\n",
    "    this_result = np.array([float(i[0][1]) for i in result_pair])\n",
    "    this_result = list(this_result.argsort().argsort() / (float(len(this_result) + 1)))\n",
    " \n",
    "    ## sum up all the predictions, and average to get final_result\n",
    "    if total_results is None:\n",
    "       total_results = this_result\n",
    "    else:\n",
    "       total_results = [i+j for i, j in zip(this_result, total_results)]\n",
    "    final_result = [i/(N+1) for i in total_results]\n",
    " \n",
    "    results_list = [(float(i), float(j[1])) for i, j in zip(final_result, result_pair)]\n",
    "    scoreAndLabels = sc.parallelize(results_list)\n",
    " \n",
    "    metrics = metric(scoreAndLabels)\n",
    "print(\"The ROC score is (@numTrees=200): \", metrics.areaUnderROC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
